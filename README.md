# Character-Cartridges-Embodied-Identity
POC for Sensemaking Systems with Emotional &amp; Anthropomorphic Traits - and synthetic identity


https://dreamtolearn.com/ryan/cognitivewingman/18/en

Character Cartridges - Embodied Identity

We are entering a magical convergence phase in media and technology. The next dozen years through 2030 are going to be very interesting as we begin to understand how to develop character and identity for sensemaking systems, leveraging AI.

Multiple technologies – including in mobile, AR, and deep learning - are rapidly converging to enable organizations to compose AI-powered systems only dreamt of in Sci-Fi novels and Hollywood movies.  

These sensemaking (and empathetic) systems will quickly enable assistants who can play roles that include a “Cognitive Wingman” – similar to the automated intelligence seen in media: JARVIS (Iron Man); KITT (Knight Rider); HAL (Space Odyssey); Samantha (Her); TARS (Interstellar).  

 
These systems will:
· Talk and listen
· Have identity
· Have relationships
· Are situationally aware
· Reason, Understand and Learn
· Understand context and remember things
· Can hold state for multiple ‘conversation turns’
· Behave in a manner that simulates emotional intelligence

 

With readily available technology - can build alpha versions of these systems today.  Mind you many POC's quite crappy – but it’s a start - and demonstrates feasibility.  And with widely available ML tools and techniques, and our human tendency to improve on things – good stuff will happen soon.

 

A key component for the creation of Digital Humans (for applications extending well beyond gaming) is a sense of identity and character.   Empathetic systems that embody cognitive elements need personality.   The best rendered face and eyes, is still just a collection of high resolution pixels – until we add voice, emotion, identity and soul.

 

Key embodiments of intelligence

So how do we begin to solve for that?

 

Well, let’s begin with a brainstorm - by segmenting into three big buckets, things that are knowable about our acronym-heavy friends above.   Most elements of our AI Cognitive Wingmen can tie out to being:

1) Declared

2) Measured

3) Calculated

 

DELCARED – this one is easy.   What’s the name of the “other”?   Is it physical or virtual form?  What’s the unique identifier, if one exists?  What is the stated purpose?  What are the ethical and moral guardrails?

 

MEASURED – measured elements are a little more complicated.  But include components that are perceivable or measurable.   Low battery?   Riding in a car?   Damaged?   Lost?  Perceiving joy or frustration in the environment from humans?  Sensing a command to behave a certain way?

 

INFERRED – if the system has been programmed to convey emotion – is it happy or sad?  (based on stimulus and interaction);   If the character is learning and evolving, what type of character is it?  Introvert/extrovert?  Confident/submissive?   Rude/polite? 

 

Some cases – behavior changing variables (extroversion, curiosity, humor) may be declared – and might be modified through an admin-level declaration.  In other cases, it may be programmatically inferred based on system’s experience.

I'm not sure if this method of organizing is the best - but it's a place to start.
Encapsulation

I grew up in the late 70’s and early 80’s.  Stranger Things indeed.   At the time, the state of the art for electronic tech (when not playing D&D) was Atart, Intellivision and ColecoVision.  The beauty of Atari and similar systems is once you decided on the game - you could grab the physical game cartridge and slam it into the console.   Then flip on the system.  80% of the time it would fire up - the other 20% you'd need to re-seat the cartridge (jiggle and retry) which usually worked

 

Now as we approach 2030 - might we learn something from the 1980's - in terms of loading one (or multiple) cartridges into the system?  Will they be fully baked characters, or character components?   Who will build the characters?  How will the identities evolve?

 

It's going to be a fun decade - I hope my generation can create something as engaging - as the developers engineers as the 1970/80's did

 

    Story and Narrative Generation
    Scene and Event Auto-creation
    Game Level Spontaneous Generation
    Game Difficulty Auto-Tuning
    Personalization & Segmentation

 
PART 2 - Proof of Concept - The Observers

https://dreamtolearn.com/internal/doc-asset/EJ3GFL3OYKWZQ3CNB03JSD911/IMG_9517.jpg

If we imagine an experiment

    Three Different "Character Types" created from (1b) bootstrap from real person or blend of people (e.g. JFK plus Ronald Reagan; or (1a) Character Template archetype)
    
    The CHARACTERS (2) can be thought of as "Observing Bots" - the watchers .  No chat, no dialog required. but they do Watch.  have emotional states (3) that are impacted by the Data/Traffic/Chatter/Context of Situation (4) - and differing REACTIONS (8) on how they see the world. different lenses
    
    OBSERVABLE world - the data - could be call center traffic, twitter streams, a twich channel in esports, unstructured observable data that is sliced along time domain (6) and analyzed (7) using standard and/or custom tools like NLC NLU NLP Tone extraction, and/or ML/DL filters 
    
    INTERPRETER considers information in front from (7) along with Character Type (2) ; Emotional State at a moment in time (3) (e.g. is the Character already upset or angry?; and (4) Context - e.g. is it appropriate to use profanity workplace (no) ; or with friends at pub (perhaps yes);
    
    SYSTEM SUM of signals - will result in some feedback on Emotional State (3) and MIGHT result - near term in simply setting a flag; if a TRIGGER (10) is reached
